{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6622a207-5d64-4691-836b-71d551bf8632",
   "metadata": {},
   "source": [
    "# A Simple Deployment\n",
    "\n",
    "Let's take an openly available model from Github and wrap it in a simple UI!\n",
    "\n",
    "[DM-Count](https://github.com/cvlab-stonybrook/DM-Count) is a model used for crowd counting.\n",
    "\n",
    "Lets download the code and load the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f7d73a-18e3-46c3-9c10-69a99f3069df",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/cvlab-stonybrook/DM-Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce13584-e019-4a49-a93f-e134ed2e8e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import gdown\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), 'DM-Count/'))\n",
    "\n",
    "import models\n",
    "\n",
    "model_path = \"model.pth\"\n",
    "url = \"https://drive.google.com/uc?id=1nnIHPaV9RGqK8JHL645zmRvkNrahD9ru\"\n",
    "gdown.download(url, model_path, quiet=False)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# load model\n",
    "model = models.vgg19() # DM-Count is VGG19 based\n",
    "model.load_state_dict(torch.load(model_path, device))\n",
    "model.eval()\n",
    "\n",
    "# send model to compute device\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa6197d-dc22-4218-9237-41ae0c2a78a9",
   "metadata": {},
   "source": [
    "## Inference Function\n",
    "\n",
    "Wrapping a single function that takes the input and returns the desired output is good programming practice.\n",
    "\n",
    "Below the `detect_crowd` function takes in an image and uses the \"DMCount\" model instantiated earler for detecting people in the image.\n",
    "\n",
    "Notice in this section we have a \"pre processing\", \"inference\", and \"post-processing\" section. These are the typical stages of \"serving\" a model's funcationality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2bf5b1-aa63-4c0d-9893-c693f872758d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "target_input_width = 1280\n",
    "target_input_height = 800\n",
    "\n",
    "def detect_crowd(original_image):\n",
    "    '''\n",
    "    Function for counting crowds in a single image\n",
    "    '''\n",
    "        \n",
    "    resized_image = cv2.resize(original_image, (target_input_width, target_input_height))\n",
    "    \n",
    "    # preprocessing    \n",
    "    image_rgb = cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB)\n",
    "    image_tensor = np.float32(image_rgb/255)\n",
    "    image_tensor = np.moveaxis(image_tensor, -1, 0)  # HWC to CHW\n",
    "    \n",
    "    image_tensor = image_tensor[np.newaxis, :] # add batch dimension\n",
    "\n",
    "    image_tensor = torch.tensor(image_tensor)\n",
    "    image_tensor = image_tensor.to(device) # move image data to compute device\n",
    "    \n",
    "    # inference\n",
    "    with torch.no_grad():\n",
    "        output, _ = model(image_tensor)\n",
    "        output = output.cpu().numpy()\n",
    "            \n",
    "    # post processing\n",
    "    crowd_count = int(np.sum(output).item())\n",
    "    \n",
    "    heatmap = output[0, 0]\n",
    "    heatmap = (heatmap - heatmap.min()) / (heatmap.max() - heatmap.min() + 1e-5)\n",
    "    heatmap = (heatmap * 255).astype(np.uint8)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n",
    "    heatmap = cv2.resize(heatmap, (target_input_width, target_input_height))\n",
    "        \n",
    "    overlayed = cv2.addWeighted(resized_image, 0.7, heatmap, 0.5, 0)\n",
    "\n",
    "    return overlayed, crowd_count\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b7fb0e-a60d-46ef-a0ab-3f3075109bbe",
   "metadata": {},
   "source": [
    "## Simple UI\n",
    "\n",
    "[Gradio](https://gradio.app/) is a fantastic little tool for building sample apps that show off ML functionality. Below is a simple interface that requires an image, and annotates a single image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a271246-3454-4f85-9ffb-4c03896ef306",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "gr.close_all() # cleanup any stray samples\n",
    "\n",
    "iface = gr.Interface(fn=detect_crowd,\n",
    "                     inputs=[\n",
    "                         gr.Image(label=\"Image of Crowd\"),\n",
    "                     ],\n",
    "                     outputs=[\n",
    "                         gr.Image(label=\"Predicted Density Map\"),\n",
    "                         gr.Label(label=\"Predicted Count\"),\n",
    "                     ],\n",
    "                     examples=[\n",
    "                         [\"sample_images/busy-road.jpg\"],\n",
    "                         [\"sample_images/concert-crowd.jpg\"],\n",
    "                         [\"sample_images/group-photo.jpg\"],\n",
    "                         [\"sample_images/mountains.jpg\"],\n",
    "                     ],\n",
    "                     title=\"Crowd Detection App\",\n",
    "                     description=\"A simple app tp find and count faces in a crowd\",\n",
    "                     )\n",
    "iface.launch(server_name=\"0.0.0.0\", server_port=7860)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e773ed8-f655-4ee1-8033-db54ae99493b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanup\n",
    "\n",
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
